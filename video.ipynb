{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDetector():\n",
    "    def __init__(self,video_path):\n",
    "        \n",
    "        self.frames_path=video_path\n",
    "        self.model_type=\"DPT_Hybrid\"\n",
    "        self.device=device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.midas = torch.hub.load(\"intel-isl/MiDaS\", self.model_type)\n",
    "\n",
    "        self.midas.to(self.device)\n",
    "        self.midas.eval()\n",
    "        \n",
    "        self.midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "        self.transform = self.midas_transforms.dpt_transform\n",
    "\n",
    "        self.model = YOLO('yolov8n-seg.pt')\n",
    "\n",
    "    def pre_works(self):\n",
    "        cap = cv2.VideoCapture(self.frames_path)\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "        ret, prev_frame = cap.read()\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        return cap,prev_gray,fps,frame_width,frame_height\n",
    "    \n",
    "    def estimate_speed(self,prev_gray,gray,fps):\n",
    "        #flow = cv2.optflow.calcOpticalFlowDenseRLOF(prev_gray, gray, None)\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        d_pixels = np.mean(np.abs(flow))\n",
    "        speed_kmh = (d_pixels * 0.05 * fps * 3.6) / 0.03  ##0.06 scale factor // ## 0.06 px başına kaç metre\n",
    "        return speed_kmh\n",
    "    \n",
    "    def midas_pred(self,img):\n",
    "        input_batch = self.transform(img).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            prediction = self.midas(input_batch)\n",
    "            prediction = torch.nn.functional.interpolate(\n",
    "                prediction.unsqueeze(1),\n",
    "                size=img.shape[:2],\n",
    "                mode='bilinear',\n",
    "                align_corners=False,\n",
    "            ).squeeze()\n",
    "        depth_map = prediction.cpu().numpy()\n",
    "        depth_map_normalized = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min())\n",
    "        depth_map = 1.0 - depth_map_normalized  # Derinliği ters çevir\n",
    "        return depth_map\n",
    "    \n",
    "    def yolo_predict(self,img):\n",
    "         results = self.model.predict(img, verbose=False, device=0)\n",
    "         return results\n",
    "    \n",
    "    def find_vehicle(self,img):\n",
    "        results=self.yolo_predict(img)\n",
    "        depth_map=self.midas_pred(img)\n",
    "        closest_vehicle=None\n",
    "        min_distance=float(\"inf\")\n",
    "        for predictions in results:\n",
    "            if predictions is None or predictions.boxes is None or predictions.masks is None:\n",
    "                continue  # Hiç nesne bulunamazsa atla\n",
    "        \n",
    "            for bbox, masks in zip(predictions.boxes, predictions.masks):\n",
    "                for scores, classes, bbox_coords in zip(bbox.conf, bbox.cls, bbox.xyxy):\n",
    "                    label = predictions.names[int(classes)]\n",
    "                    if label not in [\"car\", \"truck\", \"bus\"]:  \n",
    "                        continue  # Sadece araçları al\n",
    "\n",
    "                    xmin, ymin, xmax, ymax = map(int, bbox_coords)\n",
    "                    depth_values_bbox = depth_map[ymin:ymax, xmin:xmax]\n",
    "                    depth_value = np.median(depth_values_bbox)\n",
    "                    \n",
    "                    scale_factor = 5  # Ölçekleme faktörü (ayarlanabilir)\n",
    "                    distance = depth_value * scale_factor\n",
    "\n",
    "                    # En yakın aracı belirle\n",
    "                    if distance < min_distance:\n",
    "                       \n",
    "                        min_distance = distance\n",
    "                        closest_vehicle = (xmin, ymin, xmax, ymax, label, scores, masks)\n",
    "        if closest_vehicle:\n",
    "            xmin, ymin, xmax, ymax, label, scores, masks = closest_vehicle\n",
    "\n",
    "            # Bounding box çiz\n",
    "            cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "\n",
    "            # Derinlik bilgisini ekrana yaz\n",
    "            text = f\"{label}: {round(float(scores) * 100, 1)}% - {min_distance:.2f}m\"\n",
    "            cv2.putText(img, text, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    " \n",
    "    def __call__(self, *args, **kwds):\n",
    "        cap,prev_gray,FPS,frame_width,frame_height=self.pre_works()\n",
    "        frameId = 0\n",
    "        start_time = time.time()\n",
    "        fps = str()\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        progress_bar = tqdm(total=total_frames, desc=\"Processing Frames\", unit=\"frame\")\n",
    "       \n",
    "        fps_current=20\n",
    "        while cap.isOpened():\n",
    "            frameId+=1\n",
    "            t_ret, t_frame = cap.read()\n",
    "            img = t_frame\n",
    "            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            self.find_vehicle(img)\n",
    "            \n",
    "            \n",
    "            if frameId % 10 == 0:\n",
    "                end_time = time.time()\n",
    "                elapsed_time = end_time - start_time\n",
    "                fps_current = 10 / elapsed_time\n",
    "                fps = f'FPS: {fps_current:.2f}'\n",
    "                start_time = time.time()\n",
    "            speed_kmh=self.estimate_speed(prev_gray,gray,fps_current)\n",
    "            cv2.putText(img, fps, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(img, f\"Speed: {speed_kmh:.2f} km/h\", (-30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            cv2.imshow('Filtered Vehicle Detection', img)\n",
    "            prev_gray = gray\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                 break\n",
    "\n",
    "            progress_bar.update(1)\n",
    "        progress_bar.close()\n",
    "        cap.release()\n",
    "    \n",
    "        cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiDetector=MultiDetector(r\"speed-challenge-train.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiDetector()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altantorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
